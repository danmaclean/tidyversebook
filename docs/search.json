[
  {
    "objectID": "06-readr.html",
    "href": "06-readr.html",
    "title": "7  Loading data from files",
    "section": "",
    "text": "Questions:\n\n\nHow do I get my data into R?\n\n\nObjectives:\n\n\nLoading a ‘.csv’ file\nChecking column contents\nDealing with headers and column names\nLoading a specific sheet from a ‘.xlsx’ file.\n\n\nKeypoints:\n\n\nThe readr and readxl packages contain functions for loading data from .csv and .xslx files. These functions help you to ensure that your data is loaded as you expect."
  },
  {
    "objectID": "06-readr.html#readr",
    "href": "06-readr.html#readr",
    "title": "7  Loading data from files",
    "section": "7.2 readr",
    "text": "7.2 readr\nreadr is a tool for loading data into R. As part of the tidyverse it is loaded when you use library(tidyverse) but can be loaded on its own with library(readr). We will use readr to load in data from a ‘flat’ .csv file. Most\n\n7.2.1 read_csv()\nThe main function is read_csv() which can read a standard comma separated values file from disk into an R dataframe. There are a few variants of read_csv() which may be appropriate for different sorts of .csv file, but they all work the same.\n\nread_csv2() - reads semi-colon delimited files, which are commonly used where a comma is used as a decimal separator\nread_tsv() - reads tab delimited files\nread_delim() - reads files delimited by an arbitrary character\n\nThe first argument to read_csv() is the path to the file to read. Here I’ll read a file on my Desktop that contains the diamonds data we’ve been using.\n\n\n\n\nread_csv(\"~/Desktop/diamonds.csv\")\n\n\n\nRows: 53940 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): cut, color, clarity\ndbl (7): carat, depth, table, price, x, y, z\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 53,940 × 10\n   carat cut       color clarity depth table price     x     y     z\n   <dbl> <chr>     <chr> <chr>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# … with 53,930 more rows\n\n\nOn loading we see a column specification, read_csv() has guessed at what the columns should be and made those types. Its fine for the most part, but some of those columns we’d prefer to be factors. We can set our own column specification to force the column types on loading. We only have to do the ones that read_csv() gets wrong. Specifically, lets fix cut and color to a factor. We can do that with the col_types argument.\n\nread_csv(\"~/Desktop/diamonds.csv\",\n    col_types = cols(\n      cut = col_factor(NULL),\n      color = col_factor(NULL)\n    )\n)\n\n\n\n# A tibble: 53,940 × 10\n   carat cut       color clarity depth table price     x     y     z\n   <dbl> <fct>     <fct> <chr>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# … with 53,930 more rows\n\n\n\n\n7.2.2 Parser functions\nThis works by assigning a parser function that returns a specific type to each column, here it’s col_factor(). There are parser functions for all types of data, and all of them can be used if read_csv() doesn’t guess your data properly. We won’t go into detail of all of them, just remember that if your numbers or dates or stuff won’t load properly, there’s a parser function that can help.\nThe parser functions all have their own arguments, so we can manipulate those. We can see the NULL argument being passed to col_factor() above, which means ‘all values found should be used as levels of the factor’. This is a great default setting, but if we have a large file, it won’t help us find unexpected values.\nConsider a situation where we are certain we should only have the values Fair, Good and Very Good for cut in our diamonds data. We can make the parser function check this for us and give a warning if it finds anything else.\n\nread_csv(\"~/Desktop/diamonds.csv\",\n    col_types = cols(\n      cut = col_factor(levels = c( \"Fair\" ,\"Good\", \"Very Good\")),\n      color = col_factor(NULL)\n    )\n)\n\n\n\nWarning: One or more parsing issues, see `problems()` for details\n\n\n# A tibble: 53,940 × 10\n   carat cut       color clarity depth table price     x     y     z\n   <dbl> <fct>     <fct> <chr>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n 1  0.23 <NA>      E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 <NA>      E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 <NA>      I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# … with 53,930 more rows\n\n\nThis time, we get a large number of warnings. Though the output is quite cryptic at first glance, read_csv() is complaining that it found values for cut that were not in the list we passed to the parser function.\nHence we can use parsers to ensure we are loading in the data we expect and generate errors if not.\n\n\n7.2.3 Headers and column names\nBy default read_csv() uses the first line of the file for column names. Consider this toy example.\n\ntoy_csv <- \n\"a,b,c\n1,2,3\n4,5,6\"\nread_csv(toy_csv)\n\nRows: 2 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): a, b, c\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 2 × 3\n      a     b     c\n  <dbl> <dbl> <dbl>\n1     1     2     3\n2     4     5     6\n\n\nThe first line of the toy file becomes the column headings. This may not be appropriate, since there could be some metadata in the file\n\ntoy_csv <- \n\"some info about stuff\na,b,c\n1,2,3\n4,5,6\"\nread_csv(toy_csv)\n\nWarning: One or more parsing issues, see `problems()` for details\n\n\nRows: 3 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): some info about stuff\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 3 × 1\n  `some info about stuff`\n  <chr>                  \n1 a,b,c                  \n2 1,2,3                  \n3 4,5,6                  \n\n\nThe loaded data gets really messed up, so we can skip a set number of lines if needed\n\ntoy_csv <- \n\"some info about stuff\na,b,c\n1,2,3\n4,5,6\"\nread_csv(toy_csv, skip = 1)\n\nRows: 2 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): a, b, c\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 2 × 3\n      a     b     c\n  <dbl> <dbl> <dbl>\n1     1     2     3\n2     4     5     6\n\n\nAlternatively, you might have comments that begin with a particular character. You can use the comment argument to skip those lines\n\ntoy_csv <- \n\"#some info about stuff\n#some more info\n#goodness, lots of INFO\na,b,c\n1,2,3\n4,5,6\"\nread_csv(toy_csv, comment = \"#\")\n\nRows: 2 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): a, b, c\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 2 × 3\n      a     b     c\n  <dbl> <dbl> <dbl>\n1     1     2     3\n2     4     5     6\n\n\nThe data might not have any column names at all, the first row may data. This situation is handled with col_names argument\n\ntoy_csv <- \n\"1,2,3\n4,5,6\"\nread_csv(toy_csv, col_names = FALSE)\n\nRows: 2 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): X1, X2, X3\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 2 × 3\n     X1    X2    X3\n  <dbl> <dbl> <dbl>\n1     1     2     3\n2     4     5     6\n\n\nSo, read_csv() sets up arbitrary column names. We can specify column names if we wish\n\ntoy_csv <- \n\"a,b,c\n1,2,3\n4,5,6\"\nread_csv(toy_csv, col_names = c(\"x\", \"y\", \"z\"))\n\nRows: 3 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): x, y, z\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 3 × 3\n  x     y     z    \n  <chr> <chr> <chr>\n1 a     b     c    \n2 1     2     3    \n3 4     5     6    \n\n\n\n\n7.2.4 Missing values\nThere are many different ways of encoding missing values, you can tell read_csv() which character represents a missing value explicitly with the na argument. These values will all be loaded as proper NA.\n\ntoy_csv <- \n\"a,b,c\n1,_,3\n4,5,_\"\nread_csv(toy_csv, na = \"_\")\n\nRows: 2 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): a, b, c\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 2 × 3\n      a     b     c\n  <dbl> <dbl> <dbl>\n1     1    NA     3\n2     4     5    NA"
  },
  {
    "objectID": "06-readr.html#writing-files",
    "href": "06-readr.html#writing-files",
    "title": "7  Loading data from files",
    "section": "7.3 Writing Files",
    "text": "7.3 Writing Files\nA complementary function to read_csv() write_csv() allows you to write a dataframe out to a ‘.csv’ file. The convention is straightforward, you need the name of the dataframe and the name of the file and path to write to.\n\nwrite_csv(diamonds, \"~/Desktop/my_data.csv\")"
  },
  {
    "objectID": "06-readr.html#readxl",
    "href": "06-readr.html#readxl",
    "title": "7  Loading data from files",
    "section": "7.4 readxl",
    "text": "7.4 readxl\nThe readxl package is installed as part of the tidyverse install.packages() command, but it is not part of the core, so library(tidyverse) does not load it. You must do it explicitly with library(readxl).\n\n7.4.1 read_xlsx()\nThe main function is read_xlsx(), it’s similar to read_csv().\n\nlibrary(readxl)\nread_xlsx(\"~/Desktop/datasets.xlsx\")\n\n\n\n# A tibble: 150 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          <dbl>       <dbl>        <dbl>       <dbl> <chr>  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# … with 140 more rows\n\n\nBy default it loads the first worksheet, you can examine the sheets available with excel_sheets()\n\nexcel_sheets(\"~/Desktop/datasets.xlsx\")\n\n\n\n[1] \"iris\"     \"chickwts\" \"mtcars\"   \"quakes\"  \n\n\nThen load in the one you want.\n\nread_xlsx(\"~/Desktop/datasets.xlsx\", sheet = \"chickwts\")\n\n\n\n# A tibble: 71 × 2\n   weight feed     \n    <dbl> <chr>    \n 1    179 horsebean\n 2    160 horsebean\n 3    136 horsebean\n 4    227 horsebean\n 5    217 horsebean\n 6    168 horsebean\n 7    108 horsebean\n 8    124 horsebean\n 9    143 horsebean\n10    140 horsebean\n# … with 61 more rows\n\n\nLoading then follows the same pattern as for read_csv(), with a difference in the column specifications - in this package its much simpler. You can only specify type columnwise and the specification can only be one of “skip”, “guess”, “logical”, “numeric”, “date”, “text” or “list” - meaning you can’t do the advanced parsing as for read_csv().\nA sample spec might look like\n\nread_xlsx(\n  \"~/Desktop/datasets.xlsx\", \n  sheet = \"chickwts\",\n  col_types = c(\"numeric\", \"text\")\n  )\n\n\n\n# A tibble: 71 × 2\n   weight feed     \n    <dbl> <chr>    \n 1    179 horsebean\n 2    160 horsebean\n 3    136 horsebean\n 4    227 horsebean\n 5    217 horsebean\n 6    168 horsebean\n 7    108 horsebean\n 8    124 horsebean\n 9    143 horsebean\n10    140 horsebean\n# … with 61 more rows"
  },
  {
    "objectID": "prerequisites.html",
    "href": "prerequisites.html",
    "title": "Prerequisites",
    "section": "",
    "text": "No specific knowledge is assumed for this book, though you will need to install some software.\nYou’ll also need the following files diamonds.csv and datasets.xlsx"
  },
  {
    "objectID": "prerequisites.html#installing-r",
    "href": "prerequisites.html#installing-r",
    "title": "Prerequisites",
    "section": "Installing R",
    "text": "Installing R\nFollow this link and install the right version for your operating system https://www.stats.bris.ac.uk/R/"
  },
  {
    "objectID": "prerequisites.html#installing-rstudio",
    "href": "prerequisites.html#installing-rstudio",
    "title": "Prerequisites",
    "section": "Installing RStudio",
    "text": "Installing RStudio\nFollow this link and install the right version for your operating system https://www.rstudio.com/products/rstudio/download/"
  },
  {
    "objectID": "prerequisites.html#installing-r-packages-in-rstudio",
    "href": "prerequisites.html#installing-r-packages-in-rstudio",
    "title": "Prerequisites",
    "section": "Installing R packages in RStudio",
    "text": "Installing R packages in RStudio\nTo install all the tidyverse packages in one go start RStudio and use the Packages tab in the lower-right panel. Click the install button (top left of the panel) and enter ‘tidyverse’, then click install as in this picture\nTo complete the quizzes you’ll need a package called nycflights13. Install that in the same way."
  },
  {
    "objectID": "r-fundamentals.html",
    "href": "r-fundamentals.html",
    "title": "R Fundamentals",
    "section": "",
    "text": "Questions:\n\n\nHow do I use R?\n\n\nObjectives:\n\n\nBecome familiar with R syntax\nUnderstand the concepts of objects and assignment\nGet exposed to a few functions\n\n\nKeypoints:\n\n\nR’s capabilities are provided by functions\nR users call functions and get results"
  },
  {
    "objectID": "r-fundamentals.html#working-with-r",
    "href": "r-fundamentals.html#working-with-r",
    "title": "R Fundamentals",
    "section": "Working with R",
    "text": "Working with R\nIn this workshop we’ll use R in the extremely useful RStudio software For the most part we’ll work interactively, meaning we’ll type stuff straight into the R console in RStudio (Usually this is a window on the left or lower left) and get our results there too (usually in the consoled or in a window on the right). That’s what you see in panels like the ones below - first the thing to type into R, and below it, the calculated result from R. Let’s look at how R works by using it for it’s most basic job - as a calculator:\n\n 3 + 5\n\n[1] 8\n\n\n\n 12 * 2\n\n[1] 24\n\n\n\n 1 / 3\n\n[1] 0.3333333\n\n\n\n 12 * 2\n\n[1] 24\n\n\n\n  3 / 0\n\n[1] Inf\n\n\nFairly straightforward, we type in the expression and we get a result. That’s how this whole book will work, you type the stuff in, and get answers out. It’ll be easiest to learn if you go ahead and copy the examples one by one. Try to resist the urge to use copy and paste. Typing longhand really encourages you to look at what you’re entering.\nAs far as the R ouput itself goes, it’s really straightforward - its just the answer with a [1] stuck on the front. This [1] tells us how far through the output we are. Often R will return long lists of numbers and it can be helpful to have this extra information"
  },
  {
    "objectID": "r-fundamentals.html#variables",
    "href": "r-fundamentals.html#variables",
    "title": "R Fundamentals",
    "section": "Variables",
    "text": "Variables\nWe can save the output of operations for later use by giving it a name using the assignment symbol <-. Read this symbol as ‘gets’, so x <- 5 reads as ‘x gets 5’. These names are called variables, because the value they are associated with can change.\nLet’s give five a name, x then refer to the value 5 by it’s name. We can then use the name in place of the value. In the jargon of computing we say we are assigning a value to a variable.\n\n x <- 5\n x\n\n[1] 5\n\n\n\n x * 2\n\n[1] 10\n\n\n\ny <- 3\nx * y\n\n[1] 15\n\n\nThis is of course of limited value with just numbers but is of great value when we have large datasets, as the whole thing can be referred to by the variable.\n\nUsing objects and functions\nAt the top level, R is a simple language with two types of thing: functions and objects. As a user you will use functions to do stuff, and get back objects as an answer. Functions are easy to spot, they are a name followed by a pair of brackets like mean() is the function for calculating a mean. The options (or arguments) for the function go inside the brackets:\n\n sqrt(16)\n\n[1] 4\n\n\nOften the result from a function will be more complicated than a simple number object, often it will be a vector (simple list), like from the rnorm() function that returns lists of random numbers\n\n rnorm(100)\n\n  [1] -0.90958666  0.80847000 -0.39433115 -1.50920114  0.83735723  0.47197675\n  [7]  0.57139888  1.58936851 -1.53622066 -1.31732858  0.25666314 -0.15743264\n [13] -1.34514983 -0.40389666 -0.09796793  0.98055232  0.37425660  1.31693401\n [19]  0.14913771 -0.67412854  0.38254874  0.20105093  1.74186153 -0.61903445\n [25] -1.34557085  0.64363871 -1.43268244  0.23163807 -0.22692730  0.14827296\n [31] -2.22830115 -1.52511440  0.95231076  0.09393783 -0.01011166 -0.51219343\n [37] -0.56809410 -0.11264775  0.26079345 -1.03824051  0.54363411 -0.79109926\n [43]  1.07193023  0.33333310  1.45820522  1.07515630 -0.25311383  0.37360822\n [49]  0.89864386  0.96337874 -1.42929113 -0.08293914  1.18841676 -1.33956311\n [55]  1.21268084 -2.54939704 -2.17108675 -1.59973512  1.26778494 -0.10857833\n [61] -1.10773588 -1.41519774  0.04294372 -1.18417325 -1.62398249  2.39323153\n [67] -0.65620023  0.12149764 -0.13312641 -1.31281334  0.04359148  0.93888345\n [73]  0.47134410 -0.67211998 -1.78664746 -0.15122780 -0.21831342  1.06086396\n [79]  0.27439850  0.25946493  1.10931139  0.69319068 -0.51918802 -1.86659811\n [85] -0.17418287  0.67064996 -0.12959819  0.54079742 -0.96575493 -0.85689552\n [91] -1.09800887 -0.84057014 -0.70242987 -0.05133539 -0.33200749  0.28968192\n [97]  0.59058119 -1.28801765 -0.33072583 -0.42805094\n\n\nWe can combine objects, variables and functions to do more complex stuff in R, here’s how we get the mean of 100 random numbers.\n\nnumbers <- rnorm(100)\nmean(numbers)\n\n[1] -0.04509309\n\n\nHere we created a vector object with rnorm(100) and assigned it to the variable numbers. We than used the mean() function, passing it the variable numbers. The mean() function returned the mean of the hundred random numbers.\n\nBracket notation in this document\nI’m going to use the following descriptions for the symbols (), [] and {}:\n() are brackets, [] are square brackets {} are curly brackets"
  },
  {
    "objectID": "r-fundamentals.html#quiz",
    "href": "r-fundamentals.html#quiz",
    "title": "R Fundamentals",
    "section": "Quiz",
    "text": "Quiz\n\nCreate two variables, a and b: Add them. What happens if we change a and then re-add a and b?\nWe can also assign a + b to a new variable, c. How would you do this?\nTry some R functions: round(), c(), range(), plot() hint: Get help on a function by typing ?function_name e.g ?c(). Use the mean() function to calculate the average age of everyone in your house (Invent a housemate if you have to)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Wrangling data with ‘tidyverse’",
    "section": "",
    "text": "See Hadley Wickham’s tidy data paper - http://vita.had.co.nz/papers/tidy-data.html↩︎"
  },
  {
    "objectID": "01-tidy-data.html",
    "href": "01-tidy-data.html",
    "title": "2  Tidy Data",
    "section": "",
    "text": "Questions:\n\n\nWhat is tidy data?\n\n\nObjectives:\n\n\nUnderstanding data type\nUnderstanding tidy data structures\nExplicitly describing and checking the data structure\n\n\nKeypoints:\n\n\nData needs to be in a particular format for tidy data principles to work"
  },
  {
    "objectID": "01-tidy-data.html#tidy-data",
    "href": "01-tidy-data.html#tidy-data",
    "title": "2  Tidy Data",
    "section": "2.2 Tidy data",
    "text": "2.2 Tidy data\nThere are many ways to structure data. Here are two quite common ones.\n\n\n\n\n\ntreatment A\n\n\ntreatment B\n\n\n\nJohn Smith\n\n\n11\n\n\n2\n\n\n\n\nJane Doe\n\n\n16\n\n\n11\n\n\n\n\nMary Johnson\n\n\n3\n\n\n1\n\n\n\n\n\n\n\n\nJohn Smith\n\n\nJane Doe\n\n\nMary Johnson\n\n\n\ntreatment A\n\n\n11\n\n\n16\n\n\n3\n\n\n\n\ntreatment B\n\n\n2\n\n\n11\n\n\n1\n\n\n\n\nsource: Hadley Wickham\nTables contain two things, variables and values for those variables. In these two tables there are only three variables. treatment is one, with the values a and b . The second is ‘name’, with three values hidden in plain sight, and the third is result which is the value of the thing actually measured for each person and treatment.\nFor human reading purposes, we don’t need to state the variables explicitly, we can see them by interpolating between the columns and rows and adding a bit of common sense. This mixing up of variables and values across tables like this has led some to call these tables ‘messy’. A computer finds it hard to make sense of a messy table.\nWorking with R is made much less difficult if we get the data into a ‘tidy’ format. This format is distinct because each variable has its own column explicitly, like this\n\n\n\nname\n\n\ntreatment\n\n\nresult\n\n\n\nJohn Smith\n\n\na\n\n\n11\n\n\n\n\nJane Doe\n\n\na\n\n\n16\n\n\n\n\nMary Johnson\n\n\na\n\n\n3\n\n\n\n\nJohn Smith\n\n\nb\n\n\n2\n\n\n\n\nJane Doe\n\n\nb\n\n\n11\n\n\n\n\nMary Johnson\n\n\nb\n\n\n1\n\n\n\n\nNow each variable has a column, and each seperate observation of the data has its own row. It is much more verbose for a human, but R can use this easily because we are now explicit about what is called what and how it relates to everything else.\nMore generally put, a tidy data set should look like this, schematically.\n\n\n\n\n\nfrom Garret Grolemund - http://garrettgman.github.io/tidying/\n\n\n\n\n\nEach variable is in its own column\nEach observation is in its own row\nThe value of a variable in an observation is in a single cell."
  },
  {
    "objectID": "01-tidy-data.html#a-sample-tidy-data-set",
    "href": "01-tidy-data.html#a-sample-tidy-data-set",
    "title": "2  Tidy Data",
    "section": "2.3 A sample tidy data set",
    "text": "2.3 A sample tidy data set\nLet’s use a tidy data set that comes with the tidyverse packages. The object diamonds is built in to tidyr and can be viewed by typing its name. We’ll use the head() function to look at the top six rows only\n\nlibrary(tidyverse)\nhead(diamonds)\n\n# A tibble: 6 × 10\n  carat cut       color clarity depth table price     x     y     z\n  <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n\n\nThe output tells us that this is a thing called a tibble - this is just a table like object, more about these later. We can see the size of the tibble - 6 rows, 10 columns (this is truncated because of head() in reality its 53940 rows long). We can see the column headings and we can see the column type or, as this is called in R-speak, its class.\n\n2.3.1 Class\nEach of the columns has a particular type or class. Here class is either <dbl>, <ord> or <int>. This tells us what kind of data R is in that column. It’s very important that you and R agree about what sort of data is in each column, otherwise the operations you run can go awry.\nThankfully there are only a few main classes to worry about\n\nnum or int or dbl - number types\nchr - regular text\nfctr - A factor. A category or names for groups. Discrete values.\nlgl - TRUE or FALSE data. Can only have these two values.\n\nNumeric, logical and character are pretty self explanatory. Factors need a bit more thinking about.\n\n2.3.1.1 Factors\nA factor is a variable that can only take pre-known values called levels. Often these will be experimental categories or groups. Usually you will know the values of the level before you even start an experiment. A treatment of a plant with different chemicals could be a factor. Its levels would be names for each treatment studied. E.G GiberellicAcid, Jasmonate or Auxin. Note a factor isn’t restricted to describing inputs. In the same way, the sort of response of a plant to a treatment could be a factor, so high,low, hypersensitive could all be levels of an output factor variable in an infection assay.\nA factor can have numeric-looking levels. Treatment or response can often be labelled 1, 2, 3 etc, but they are used as categories, not actual measurements or numbers in factors. If the values can be replaced by e.g A, B, C without loss of sense, then the variable is a category and should be encoded as a factor.\nIn our diamonds data set, the cut, color and clarity variables are factors - they just happen to be a particular sort of ordered factor.\nFactors are what we will group and split our data sets by. We will do statistics, plots and comparisons based on numbers within factor levels.\n\n\n2.3.1.2 Checking Class Explicitly\nThe tibble table-like object of our diamonds data does a good job of summarising type. R has some commands for this too.\nclass() will give you the class(es) of a specific variable (we can use the $ notation to get a single column out of a table-like object such as a tibble)\n\nclass(diamonds$cut)\n\n[1] \"ordered\" \"factor\" \n\n\nlevels() will tell you all the levels of a factor\n\nlevels(diamonds$cut)\n\n[1] \"Fair\"      \"Good\"      \"Very Good\" \"Premium\"   \"Ideal\"    \n\n\nstr() will give you a summary of whole table-like objects\n\nstr(diamonds)\n\ntibble [53,940 × 10] (S3: tbl_df/tbl/data.frame)\n $ carat  : num [1:53940] 0.23 0.21 0.23 0.29 0.31 0.24 0.24 0.26 0.22 0.23 ...\n $ cut    : Ord.factor w/ 5 levels \"Fair\"<\"Good\"<..: 5 4 2 4 2 3 3 3 1 3 ...\n $ color  : Ord.factor w/ 7 levels \"D\"<\"E\"<\"F\"<\"G\"<..: 2 2 2 6 7 7 6 5 2 5 ...\n $ clarity: Ord.factor w/ 8 levels \"I1\"<\"SI2\"<\"SI1\"<..: 2 3 5 4 2 6 7 3 4 5 ...\n $ depth  : num [1:53940] 61.5 59.8 56.9 62.4 63.3 62.8 62.3 61.9 65.1 59.4 ...\n $ table  : num [1:53940] 55 61 65 58 58 57 57 55 61 61 ...\n $ price  : int [1:53940] 326 326 327 334 335 336 336 337 337 338 ...\n $ x      : num [1:53940] 3.95 3.89 4.05 4.2 4.34 3.94 3.95 4.07 3.87 4 ...\n $ y      : num [1:53940] 3.98 3.84 4.07 4.23 4.35 3.96 3.98 4.11 3.78 4.05 ...\n $ z      : num [1:53940] 2.43 2.31 2.31 2.63 2.75 2.48 2.47 2.53 2.49 2.39 ..."
  },
  {
    "objectID": "01-tidy-data.html#quiz",
    "href": "01-tidy-data.html#quiz",
    "title": "2  Tidy Data",
    "section": "2.4 Quiz",
    "text": "2.4 Quiz\n\nHow many levels in the factor color in the diamonds data?\nIs the table below ‘tidy’?\n\n\n\n\n\n\ncountry\nyear\ntype\ncount\n\n\n\n\nAfghanistan\n1999\ncases\n745\n\n\nAfghanistan\n1999\npopulation\n19987071\n\n\nAfghanistan\n2000\ncases\n2666\n\n\nAfghanistan\n2000\npopulation\n20595360\n\n\nBrazil\n1999\ncases\n37737\n\n\nBrazil\n1999\npopulation\n172006362\n\n\nBrazil\n2000\ncases\n80488\n\n\nBrazil\n2000\npopulation\n174504898\n\n\nChina\n1999\ncases\n212258\n\n\nChina\n1999\npopulation\n1272915272\n\n\nChina\n2000\ncases\n213766\n\n\nChina\n2000\npopulation\n1280428583\n\n\n\n\n\n\nHow many variables are contained in the table - how many columns should there be for it to be tidy?"
  },
  {
    "objectID": "02-dplyr-verbs.html",
    "href": "02-dplyr-verbs.html",
    "title": "3  dplyr Verbs",
    "section": "",
    "text": "Questions:\n\n\nHow do I manipulate tidy data?\n\n\nObjectives:\n\n\nUnderstanding the pipe syntax\nWorking with the 6 main functions\nOverview of helper functions\n\n\nKeypoints:\n\n\nTidy data can be operated on with six main functions that can quickly split, apply summaries and combine sub-groups of data"
  },
  {
    "objectID": "02-dplyr-verbs.html#dplyr",
    "href": "02-dplyr-verbs.html#dplyr",
    "title": "3  dplyr Verbs",
    "section": "3.2 dplyr",
    "text": "3.2 dplyr\ndplyr (data plier) is a tool for manipulating datasets. As part of the tidyverse it is loaded when you use library(tidyverse) but can be loaded on it’s own with library(dplyr). dplyr is set up as a small grammar, it has five main verbs that help you form small ‘sentences’ to get to your result.\nThe verbs are:\n\nselect() picks variables based on their names.\nfilter() picks cases based on their values.\nmutate() adds new variables that are functions of existing variables\nsummarise() reduces multiple values down to a single summary.\narrange() changes the ordering of the rows.\n\nA sixth function group_by() allows you to operate on subsets of the data."
  },
  {
    "objectID": "02-dplyr-verbs.html#pipe-syntax",
    "href": "02-dplyr-verbs.html#pipe-syntax",
    "title": "3  dplyr Verbs",
    "section": "3.3 Pipe Syntax",
    "text": "3.3 Pipe Syntax\nThe first argument to all these functions is the tidy table-like object (we’ll start calling these data frames from here), so for our diamonds data set, then we use\n\nfilter(diamonds, ... ) # ... stands in for other arguments\n\nIf we want to perform more than one step in series, we end up in the situation of having to save our result with a new name and working from there. This gets cumbersome quickly…\n\ndiamonds2 <- filter(diamonds, ...)\ndiamonds3 <- select(diamonds2, ...)\ndiamonds4 <- mutate(diamonds3, ...)\n\nTo avoid this, there is a pipe operator - %>%. The purpose of the pipe is to take the thing on its left, and use it as the first argument of the thing on its right. So we can change that mess to\n\ndiamonds %>% filter( ... ) %>% select( ... ) %>% mutate( ... )\n\nWhich is much more readable. Further we can put the right hand side of the pipe on a new line, such that we can get a very easy to read pattern.\n\ndiamonds %>%\n  filter( ... ) %>%\n  select( ... ) %>% \n  mutate( ... )\n\nIf you want to save the result, you’ll just put the usual assign at the top\n\nfiltered_diamonds <- \ndiamonds %>%\n  filter( ... ) %>%\n  select( ... ) %>% \n  mutate( ... )"
  },
  {
    "objectID": "02-dplyr-verbs.html#select",
    "href": "02-dplyr-verbs.html#select",
    "title": "3  dplyr Verbs",
    "section": "3.4 select()",
    "text": "3.4 select()\nselect() is probably the simplest verb. It lets you select whole columns from the dataframe, discarding others. This is most useful for working with huge datasets of many columns, or for extracting bits for ease of printing or presentation.\n\n\n\n\ndiamonds %>% \n  select(carat, cut)\n\n# A tibble: 53,940 × 2\n   carat cut      \n   <dbl> <ord>    \n 1  0.23 Ideal    \n 2  0.21 Premium  \n 3  0.23 Good     \n 4  0.29 Premium  \n 5  0.31 Good     \n 6  0.24 Very Good\n 7  0.24 Very Good\n 8  0.26 Very Good\n 9  0.22 Fair     \n10  0.23 Very Good\n# … with 53,930 more rows\n\n\nShorthands include the : which lets you choose a range and - which can be read as except so leaves out the columns you state\n\ndiamonds %>%\n  select(depth:price) \n\n# A tibble: 53,940 × 3\n   depth table price\n   <dbl> <dbl> <int>\n 1  61.5    55   326\n 2  59.8    61   326\n 3  56.9    65   327\n 4  62.4    58   334\n 5  63.3    58   335\n 6  62.8    57   336\n 7  62.3    57   336\n 8  61.9    55   337\n 9  65.1    61   337\n10  59.4    61   338\n# … with 53,930 more rows\n\n\n\ndiamonds %>%\n  select( -x, -y, -z)\n\n# A tibble: 53,940 × 7\n   carat cut       color clarity depth table price\n   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int>\n 1  0.23 Ideal     E     SI2      61.5    55   326\n 2  0.21 Premium   E     SI1      59.8    61   326\n 3  0.23 Good      E     VS1      56.9    65   327\n 4  0.29 Premium   I     VS2      62.4    58   334\n 5  0.31 Good      J     SI2      63.3    58   335\n 6  0.24 Very Good J     VVS2     62.8    57   336\n 7  0.24 Very Good I     VVS1     62.3    57   336\n 8  0.26 Very Good H     SI1      61.9    55   337\n 9  0.22 Fair      E     VS2      65.1    61   337\n10  0.23 Very Good H     VS1      59.4    61   338\n# … with 53,930 more rows\n\n\nYou can select columns with helpers,\n\nstarts_with()\nends_with()\ncontains()\nnum_range()\n\nHere are examples.\n\ndiamonds %>%\n  select( starts_with(\"c\"))\n\n# A tibble: 53,940 × 4\n   carat cut       color clarity\n   <dbl> <ord>     <ord> <ord>  \n 1  0.23 Ideal     E     SI2    \n 2  0.21 Premium   E     SI1    \n 3  0.23 Good      E     VS1    \n 4  0.29 Premium   I     VS2    \n 5  0.31 Good      J     SI2    \n 6  0.24 Very Good J     VVS2   \n 7  0.24 Very Good I     VVS1   \n 8  0.26 Very Good H     SI1    \n 9  0.22 Fair      E     VS2    \n10  0.23 Very Good H     VS1    \n# … with 53,930 more rows\n\n\n\ndiamonds %>%\n  select( ends_with(\"e\")) \n\n# A tibble: 53,940 × 2\n   table price\n   <dbl> <int>\n 1    55   326\n 2    61   326\n 3    65   327\n 4    58   334\n 5    58   335\n 6    57   336\n 7    57   336\n 8    55   337\n 9    61   337\n10    61   338\n# … with 53,930 more rows\n\n\n\ndiamonds %>%\n  select( contains(\"l\"))\n\n# A tibble: 53,940 × 3\n   color clarity table\n   <ord> <ord>   <dbl>\n 1 E     SI2        55\n 2 E     SI1        61\n 3 E     VS1        65\n 4 I     VS2        58\n 5 J     SI2        58\n 6 J     VVS2       57\n 7 I     VVS1       57\n 8 H     SI1        55\n 9 E     VS2        61\n10 H     VS1        61\n# … with 53,930 more rows\n\n\n\n3.4.1 rename()\nOften when you’re selecting columns to work on, you’ll need to fix the names - rename() is useful for this. Let’s fix that mis-spelled column\n\ndiamonds %>% \n  rename( colour = color)\n\n# A tibble: 53,940 × 10\n   carat cut       colour clarity depth table price     x     y     z\n   <dbl> <ord>     <ord>  <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n 1  0.23 Ideal     E      SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E      SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E      VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I      VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J      SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J      VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I      VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H      SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E      VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H      VS1      59.4    61   338  4     4.05  2.39\n# … with 53,930 more rows"
  },
  {
    "objectID": "02-dplyr-verbs.html#filter",
    "href": "02-dplyr-verbs.html#filter",
    "title": "3  dplyr Verbs",
    "section": "3.5 filter()",
    "text": "3.5 filter()\nThe filter() function lets you select rows (observations) from your data frame based on criteria you specify. Here I’ll look for all rows with a value of G for the color variable (I’ll also pipe the output to the head() function to view just the top of the output.)\n\ndiamonds %>%\n  filter( color == \"G\")\n\n# A tibble: 11,292 × 10\n   carat cut       color clarity depth table price     x     y     z\n   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n 1  0.23 Very Good G     VVS2     60.4    58   354  3.97  4.01  2.41\n 2  0.23 Ideal     G     VS1      61.9    54   404  3.93  3.95  2.44\n 3  0.28 Ideal     G     VVS2     61.4    56   553  4.19  4.22  2.58\n 4  0.31 Very Good G     SI1      63.3    57   553  4.33  4.3   2.73\n 5  0.31 Premium   G     SI1      61.8    58   553  4.35  4.32  2.68\n 6  0.24 Premium   G     VVS1     62.3    59   554  3.95  3.92  2.45\n 7  0.7  Ideal     G     VS2      61.6    56  2757  5.7   5.67  3.5 \n 8  0.78 Very Good G     SI2      63.8    56  2759  5.81  5.85  3.72\n 9  0.74 Ideal     G     SI1      61.6    55  2760  5.8   5.85  3.59\n10  0.75 Premium   G     VS2      61.7    58  2760  5.85  5.79  3.59\n# … with 11,282 more rows\n\n\nThe syntax is fairly clear, just pass the column you want to think about and the condition to keep the rows. Multiple conditions can be used and all must be true to keep a row.\n\ndiamonds %>%\n  filter( color == \"G\", \n          cut == \"Ideal\" )\n\n# A tibble: 4,884 × 10\n   carat cut   color clarity depth table price     x     y     z\n   <dbl> <ord> <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n 1  0.23 Ideal G     VS1      61.9    54   404  3.93  3.95  2.44\n 2  0.28 Ideal G     VVS2     61.4    56   553  4.19  4.22  2.58\n 3  0.7  Ideal G     VS2      61.6    56  2757  5.7   5.67  3.5 \n 4  0.74 Ideal G     SI1      61.6    55  2760  5.8   5.85  3.59\n 5  0.75 Ideal G     SI1      62.2    55  2760  5.87  5.8   3.63\n 6  0.71 Ideal G     VS2      62.4    54  2762  5.72  5.76  3.58\n 7  0.64 Ideal G     VVS1     61.9    56  2766  5.53  5.56  3.43\n 8  0.71 Ideal G     VS2      61.9    57  2771  5.73  5.77  3.56\n 9  0.58 Ideal G     VVS1     61.5    55  2772  5.39  5.44  3.33\n10  0.72 Ideal G     SI1      61.8    56  2776  5.72  5.75  3.55\n# … with 4,874 more rows\n\n\nTo make more complex queries, you’ll need to combine comparisons and logical operators.\n\n3.5.1 Comparisons\nR provides the following comparison operators\n\n== - strictly equal to\n!= - not equal to\n>, <, >=, <= - greater than, less than, greater or equal to, less or equal to\n\nThese all work as you might expect. Except for ==. Trying to use == on numbers with a decimal point is tricky because of rounding errors in the computer. See this:\n\n(1 / 49) * 49 == 1\n\n[1] FALSE\n\n\nThis statement is asking ‘is 1 divided by 49, multiplied by 49, equal to 1’. The computer says FALSE because the computer can’t store infinite numbers of decimal places. The rounding error is extremely small (down to the last 16th decimal place) but it is there. To deal with this rounding error we use the near() function, which checks numbers are the same to about the 8th decimal place.\n\nnear( (1 / 49) * 49, 1)\n\n[1] TRUE\n\n\n\n\n3.5.2 Logical operators\nfilter() uses combinations of R logical operators, these are & for and, | for or and ! for not. You can build filters with these. Let’s modify our query to find color G or cut ideal.\n\ndiamonds %>%\n  filter( color == \"G\" | cut == \"Ideal\" )\n\n# A tibble: 27,959 × 10\n   carat cut       color clarity depth table price     x     y     z\n   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.23 Ideal     J     VS1      62.8    56   340  3.93  3.9   2.46\n 3  0.31 Ideal     J     SI2      62.2    54   344  4.35  4.37  2.71\n 4  0.3  Ideal     I     SI2      62      54   348  4.31  4.34  2.68\n 5  0.23 Very Good G     VVS2     60.4    58   354  3.97  4.01  2.41\n 6  0.33 Ideal     I     SI2      61.8    55   403  4.49  4.51  2.78\n 7  0.33 Ideal     I     SI2      61.2    56   403  4.49  4.5   2.75\n 8  0.33 Ideal     J     SI1      61.1    56   403  4.49  4.55  2.76\n 9  0.23 Ideal     G     VS1      61.9    54   404  3.93  3.95  2.44\n10  0.32 Ideal     I     SI1      60.9    55   404  4.45  4.48  2.72\n# … with 27,949 more rows\n\n\nNote that the computer doesn’t read this like it’s English. Consider this\n\ndiamonds %>%\n  filter( color == \"G\" | \"F\")\n\nYou might consider this to read filter rows with color column equal toGorF`. The computer doesn’t read it like this. It needs more explicit statements\n\ndiamonds %>%\n  filter( color == \"G\" | color == \"F\")\n\n# A tibble: 20,834 × 10\n   carat cut       color clarity depth table price     x     y     z\n   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n 1  0.22 Premium   F     SI1      60.4    61   342  3.88  3.84  2.33\n 2  0.23 Very Good G     VVS2     60.4    58   354  3.97  4.01  2.41\n 3  0.23 Very Good F     VS1      60.9    57   357  3.96  3.99  2.42\n 4  0.23 Very Good F     VS1      60      57   402  4     4.03  2.41\n 5  0.23 Very Good F     VS1      59.8    57   402  4.04  4.06  2.42\n 6  0.23 Good      F     VS1      58.2    59   402  4.06  4.08  2.37\n 7  0.29 Premium   F     SI1      62.4    58   403  4.24  4.26  2.65\n 8  0.24 Very Good F     SI1      60.9    61   404  4.02  4.03  2.45\n 9  0.23 Ideal     G     VS1      61.9    54   404  3.93  3.95  2.44\n10  0.28 Ideal     G     VVS2     61.4    56   553  4.19  4.22  2.58\n# … with 20,824 more rows\n\n\nWhich can be cumbersome if you want to filter on one of many possible values. For that reason we have %in% , which works like\n\ndiamonds %>%\n  filter( color  %in% c(\"G\", \"F\") )\n\n# A tibble: 20,834 × 10\n   carat cut       color clarity depth table price     x     y     z\n   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n 1  0.22 Premium   F     SI1      60.4    61   342  3.88  3.84  2.33\n 2  0.23 Very Good G     VVS2     60.4    58   354  3.97  4.01  2.41\n 3  0.23 Very Good F     VS1      60.9    57   357  3.96  3.99  2.42\n 4  0.23 Very Good F     VS1      60      57   402  4     4.03  2.41\n 5  0.23 Very Good F     VS1      59.8    57   402  4.04  4.06  2.42\n 6  0.23 Good      F     VS1      58.2    59   402  4.06  4.08  2.37\n 7  0.29 Premium   F     SI1      62.4    58   403  4.24  4.26  2.65\n 8  0.24 Very Good F     SI1      60.9    61   404  4.02  4.03  2.45\n 9  0.23 Ideal     G     VS1      61.9    54   404  3.93  3.95  2.44\n10  0.28 Ideal     G     VVS2     61.4    56   553  4.19  4.22  2.58\n# … with 20,824 more rows\n\n\nYou can select anything not in a list given to %in% with a judicious ! (not), again this is a bit weird if you translate directly from English, as the not goes first.\n\ndiamonds %>%\n  filter( ! color %in% c(\"G\", \"F\") )\n\n# A tibble: 33,106 × 10\n   carat cut       color clarity depth table price     x     y     z\n   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# … with 33,096 more rows"
  },
  {
    "objectID": "02-dplyr-verbs.html#mutate",
    "href": "02-dplyr-verbs.html#mutate",
    "title": "3  dplyr Verbs",
    "section": "3.6 mutate()",
    "text": "3.6 mutate()\nThe mutate() function lets you add new columns based on values in other columns. Note that doing so to this data set makes it too big to print, so I’ll select() the appropriate columns.\n\ndiamonds %>%\n  mutate(price_per_carat = price / carat) %>%\n  select(price, carat, price_per_carat)\n\n# A tibble: 53,940 × 3\n   price carat price_per_carat\n   <int> <dbl>           <dbl>\n 1   326  0.23           1417.\n 2   326  0.21           1552.\n 3   327  0.23           1422.\n 4   334  0.29           1152.\n 5   335  0.31           1081.\n 6   336  0.24           1400 \n 7   336  0.24           1400 \n 8   337  0.26           1296.\n 9   337  0.22           1532.\n10   338  0.23           1470.\n# … with 53,930 more rows\n\n\nYou can refer to columns straight after creating them, so you can minimise mutate()s\n\ndiamonds %>%\n  mutate(price_per_carat = price / carat,\n         depth_per_ppc = depth / price_per_carat) %>%\n  select(depth_per_ppc, price_per_carat) \n\n# A tibble: 53,940 × 2\n   depth_per_ppc price_per_carat\n           <dbl>           <dbl>\n 1        0.0434           1417.\n 2        0.0385           1552.\n 3        0.0400           1422.\n 4        0.0542           1152.\n 5        0.0586           1081.\n 6        0.0449           1400 \n 7        0.0445           1400 \n 8        0.0478           1296.\n 9        0.0425           1532.\n10        0.0404           1470.\n# … with 53,930 more rows\n\n\n\n3.6.1 Functions in mutate()\nYou can create a new column with mutate() using pretty much any vectorized R function. It’s a bit complicated to explain what I mean by ‘vectorized’ so let’s start with some examples.\n\ndiamonds %>% \n  mutate(log_price = log(price)) %>%\n  select(-x, -y, -z) \n\n# A tibble: 53,940 × 8\n   carat cut       color clarity depth table price log_price\n   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int>     <dbl>\n 1  0.23 Ideal     E     SI2      61.5    55   326      5.79\n 2  0.21 Premium   E     SI1      59.8    61   326      5.79\n 3  0.23 Good      E     VS1      56.9    65   327      5.79\n 4  0.29 Premium   I     VS2      62.4    58   334      5.81\n 5  0.31 Good      J     SI2      63.3    58   335      5.81\n 6  0.24 Very Good J     VVS2     62.8    57   336      5.82\n 7  0.24 Very Good I     VVS1     62.3    57   336      5.82\n 8  0.26 Very Good H     SI1      61.9    55   337      5.82\n 9  0.22 Fair      E     VS2      65.1    61   337      5.82\n10  0.23 Very Good H     VS1      59.4    61   338      5.82\n# … with 53,930 more rows\n\n\n\ndiamonds %>%\n  mutate( total_price = sum(price)) %>%\n  select( -x, -y, -z) \n\n# A tibble: 53,940 × 8\n   carat cut       color clarity depth table price total_price\n   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int>       <int>\n 1  0.23 Ideal     E     SI2      61.5    55   326   212135217\n 2  0.21 Premium   E     SI1      59.8    61   326   212135217\n 3  0.23 Good      E     VS1      56.9    65   327   212135217\n 4  0.29 Premium   I     VS2      62.4    58   334   212135217\n 5  0.31 Good      J     SI2      63.3    58   335   212135217\n 6  0.24 Very Good J     VVS2     62.8    57   336   212135217\n 7  0.24 Very Good I     VVS1     62.3    57   336   212135217\n 8  0.26 Very Good H     SI1      61.9    55   337   212135217\n 9  0.22 Fair      E     VS2      65.1    61   337   212135217\n10  0.23 Very Good H     VS1      59.4    61   338   212135217\n# … with 53,930 more rows\n\n\nObserve how the same number is in all the rows in the last example, this highlights how this ‘vectorized’ function idea works.\nBriefly, vectorized functions work on whole columns at a time, not just single rows. So if it makes sense to treat each element of the column individually, the function will do that. Consider this column (here printed on its side) with the log() function.\n\nlog(c(1,2,3))\n\n[1] 0.0000000 0.6931472 1.0986123\n\n\nYou get back a column of numbers the same length as you put in, each item logged. With the sum() function it makes sense to return the sum of all the numbers in the column.\n\nsum(c(1,2,3))\n\n[1] 6\n\n\nSo you get back a single number. The behaviour of mutate() then is akin to taking the whole column or columns you specify, apply whatever function you ask for and putting the resulting column in the dataframe. If the resulting column is of length one, that just gets repeated until it fits. That is why we get repeats of the same number in the sum() example and why that number is the sum of all the prices.\nIf the result from the function isn’t the same length as the column or has length of one - the function will fail. Most common functions will work nicely though.\n\n\n3.6.2 if_else()\nOne final vectorized function is if_else(), this is useful when you want to add a column that annotates the data with an arbitrary value based on values. Let’s add a column called cost that can be high or low depending on the price.\n\ndiamonds %>%\n  mutate( cost = if_else( price > 335, \"high\", \"low\")) %>%\n  select( -x, -y, -z)\n\n# A tibble: 53,940 × 8\n   carat cut       color clarity depth table price cost \n   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <chr>\n 1  0.23 Ideal     E     SI2      61.5    55   326 low  \n 2  0.21 Premium   E     SI1      59.8    61   326 low  \n 3  0.23 Good      E     VS1      56.9    65   327 low  \n 4  0.29 Premium   I     VS2      62.4    58   334 low  \n 5  0.31 Good      J     SI2      63.3    58   335 low  \n 6  0.24 Very Good J     VVS2     62.8    57   336 high \n 7  0.24 Very Good I     VVS1     62.3    57   336 high \n 8  0.26 Very Good H     SI1      61.9    55   337 high \n 9  0.22 Fair      E     VS2      65.1    61   337 high \n10  0.23 Very Good H     VS1      59.4    61   338 high \n# … with 53,930 more rows\n\n\nThe if_else() function then just adds the first value (“high”) if the condition is ‘true’ else it puts the second value."
  },
  {
    "objectID": "02-dplyr-verbs.html#summarize-and-group_by",
    "href": "02-dplyr-verbs.html#summarize-and-group_by",
    "title": "3  dplyr Verbs",
    "section": "3.7 summarize() and group_by()",
    "text": "3.7 summarize() and group_by()\nThe summarize() function is a reductive function. It reduces entire dataframes to a single row, and returns an entirely new dataframe.\n\ndiamonds %>%\n  summarize( mean_price = mean(price) )\n\n# A tibble: 1 × 1\n  mean_price\n       <dbl>\n1      3933.\n\n\nsummarize() is best used with group_by() which helps split dataframes into subsets. The summarize() function will run once for each subset created by group_by(). Let’s find the mean price for every colour of diamonds. We’ll do this by grouping the diamonds dataframe on color, then summarising.\n\ndiamonds %>%\n  group_by(color) %>%\n  summarize(mean_price = mean(price) ) \n\n# A tibble: 7 × 2\n  color mean_price\n  <ord>      <dbl>\n1 D          3170.\n2 E          3077.\n3 F          3725.\n4 G          3999.\n5 H          4487.\n6 I          5092.\n7 J          5324.\n\n\nThis is where the power of dplyr starts to be obvious. Once we’ve got our dataframe into shape with the select(), filter() and mutate() functions, we can start to compute new information with group_by() and summarize() and some of the helper functions.\nLet’s group by two things, color and cut, and get the mean and standard deviation of price.\n\ndiamonds %>%\n  group_by(color, cut) %>%\n  summarize( \n    mean_price = mean(price),\n    sd = sd(price)\n    )\n\n`summarise()` has grouped output by 'color'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 35 × 4\n# Groups:   color [7]\n   color cut       mean_price    sd\n   <ord> <ord>          <dbl> <dbl>\n 1 D     Fair           4291. 3286.\n 2 D     Good           3405. 3175.\n 3 D     Very Good      3470. 3524.\n 4 D     Premium        3631. 3712.\n 5 D     Ideal          2629. 3001.\n 6 E     Fair           3682. 2977.\n 7 E     Good           3424. 3331.\n 8 E     Very Good      3215. 3408.\n 9 E     Premium        3539. 3795.\n10 E     Ideal          2598. 2956.\n# … with 25 more rows\n\n\nNote how every combination of color and cut is made into subsets.\n\n3.7.1 Helpful summarize() functions\nThere are numerous helpful summary functions. We’ve already seen mean() , sum() and sd().\nThe function n() counts the number of items in a group. It doesn’t need a column name to work on.\n\ndiamonds %>%\n  group_by(color) %>%\n  summarize( \n     count = n()\n    )\n\n# A tibble: 7 × 2\n  color count\n  <ord> <int>\n1 D      6775\n2 E      9797\n3 F      9542\n4 G     11292\n5 H      8304\n6 I      5422\n7 J      2808\n\n\nRelated is n_distinct() which counts the number of unique values in a group. This one needs to know which column of things you want to use. Let’s see how many observations there are for each cut and how many different colors are observed in each cut\n\ndiamonds %>%\n  group_by(cut) %>%\n  summarize( \n     items = n(),\n     unique_colors = n_distinct(color)\n    )\n\n# A tibble: 5 × 3\n  cut       items unique_colors\n  <ord>     <int>         <int>\n1 Fair       1610             7\n2 Good       4906             7\n3 Very Good 12082             7\n4 Premium   13791             7\n5 Ideal     21551             7\n\n\nThere are other helpful summary functions, here’s a non-exhaustive list\n\nmax() or min() - maximum or minimum value in a column\nmedian() - median value in a column\nIQR() - interquartile range (distance) between 25th and 75th percentile\nfirst() or last() - first or last values in a column"
  },
  {
    "objectID": "02-dplyr-verbs.html#arrange",
    "href": "02-dplyr-verbs.html#arrange",
    "title": "3  dplyr Verbs",
    "section": "3.8 arrange()",
    "text": "3.8 arrange()\nThe arrange() function is a straightforward function that helps you arrange the final table from summarize() a bit more nicely. It simply orders the rows in a way that you specify.\n\ndiamonds %>% \n  arrange(price)\n\n# A tibble: 53,940 × 10\n   carat cut       color clarity depth table price     x     y     z\n   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n 1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n 2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n 3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n 4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n 5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n 6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n 7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n 8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n 9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n# … with 53,930 more rows\n\n\nTo sort biggest first, use desc()\n\ndiamonds %>% \n  arrange(desc(price)) \n\n# A tibble: 53,940 × 10\n   carat cut       color clarity depth table price     x     y     z\n   <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n 1  2.29 Premium   I     VS2      60.8    60 18823  8.5   8.47  5.16\n 2  2    Very Good G     SI1      63.5    56 18818  7.9   7.97  5.04\n 3  1.51 Ideal     G     IF       61.7    55 18806  7.37  7.41  4.56\n 4  2.07 Ideal     G     SI2      62.5    55 18804  8.2   8.13  5.11\n 5  2    Very Good H     SI1      62.8    57 18803  7.95  8     5.01\n 6  2.29 Premium   I     SI1      61.8    59 18797  8.52  8.45  5.24\n 7  2.04 Premium   H     SI1      58.1    60 18795  8.37  8.28  4.84\n 8  2    Premium   I     VS1      60.8    59 18795  8.13  8.02  4.91\n 9  1.71 Premium   F     VS2      62.3    59 18791  7.57  7.53  4.7 \n10  2.15 Ideal     G     SI2      62.6    54 18791  8.29  8.35  5.21\n# … with 53,930 more rows"
  },
  {
    "objectID": "02-dplyr-verbs.html#missing-values",
    "href": "02-dplyr-verbs.html#missing-values",
    "title": "3  dplyr Verbs",
    "section": "3.9 Missing Values",
    "text": "3.9 Missing Values\nMany (many!) datasets will have some missing values at some points. These are encoded in R as NA. They need to be dealt with explicitly as they mess up lots of calculations.\nLook at the toy dataframe incomplete below\n\n\n\n\nincomplete\n\n  group size\n1     A 10.4\n2     B   NA\n3     C  8.0\n4     A  6.0\n5     B   NA\n6     C   NA\n\n\nWhen we try to summarize() we get stuck\n\nincomplete %>%\n  group_by( group ) %>%\n  summarize(mean_size = mean(size))\n\n# A tibble: 3 × 2\n  group mean_size\n  <chr>     <dbl>\n1 A           8.2\n2 B          NA  \n3 C          NA  \n\n\nThe groups with any NA can’t be calculated. We need to tell our helper function to remove NA before we work with it.\n\nincomplete %>%\n  group_by( group ) %>%\n  summarize(mean_size = mean(size, na.rm = TRUE))\n\n# A tibble: 3 × 2\n  group mean_size\n  <chr>     <dbl>\n1 A           8.2\n2 B         NaN  \n3 C           8  \n\n\nThis works! Though because the group B only had NA in it the formula for mean fails because we can’t divide by 0 and we get NaN (not a number).\nYou might think you can use filter() to get rid of any rows with NA in, but you get a weird result\n\nincomplete %>%\n  filter(size != NA) %>%\n  group_by( group ) %>%\n  summarize(mean_size = mean(size))\n\n# A tibble: 0 × 2\n# … with 2 variables: group <chr>, mean_size <dbl>\n\n\nBy definition NA means Not available, which is a nice way of saying don't know, so, strictly, x == NA means “is x equal to something we don’t know the value of?” To which the answer can only be don't know, for which R uses NA. The result is that any comparison with NA in it is NA. filter() doesn’t know whether any row passes so throws it out. You get no rows for group_by() to group.\nIf you want to check something is an NA, you can use is.na()\n\nincomplete %>%\n  filter(! is.na(size)) %>%\n  group_by( group ) %>%\n  summarize(mean_size = mean(size))\n\n# A tibble: 2 × 2\n  group mean_size\n  <chr>     <dbl>\n1 A           8.2\n2 C           8  \n\n\nNote that you lose the information for the B group, which may be important.\nYou may want to pair these operations with an n() column to give you an idea of how many values you use to get your answer.\n\nincomplete %>%\n  group_by( group ) %>%\n  summarize(\n    mean_size = mean(size, na.rm = TRUE),\n    sample_size = n()\n    )\n\n# A tibble: 3 × 3\n  group mean_size sample_size\n  <chr>     <dbl>       <int>\n1 A           8.2           2\n2 B         NaN             2\n3 C           8             2\n\n\n\nincomplete %>%\n  filter(! is.na(size)) %>%\n  group_by( group ) %>%\n  summarize(mean_size = mean(size),\n    sample_size = n()\n    \n    )\n\n# A tibble: 2 × 3\n  group mean_size sample_size\n  <chr>     <dbl>       <int>\n1 A           8.2           2\n2 C           8             1\n\n\nWith a more complicated call, you can explicitly get the number of NAs.\n\nincomplete %>%\n  group_by( group ) %>%\n  summarize(\n    mean_size = mean(size, na.rm = TRUE),\n    sample_size = n(),\n    nas = sum(is.na(size))\n    )\n\n# A tibble: 3 × 4\n  group mean_size sample_size   nas\n  <chr>     <dbl>       <int> <int>\n1 A           8.2           2     0\n2 B         NaN             2     2\n3 C           8             2     1"
  },
  {
    "objectID": "02-dplyr-verbs.html#quiz",
    "href": "02-dplyr-verbs.html#quiz",
    "title": "3  dplyr Verbs",
    "section": "3.10 Quiz",
    "text": "3.10 Quiz\n\nLoad the package nycflights13 which is a tidy data set of flight information out of New York. Look at the flights table that has been loaded and note the column names and types.\nThe individual planes are identified by their tailnum. Which plane has the worst on-time record?\nWhat time of day should you fly to avoid delays as much as possible?\nFor each destination compute the total minutes of delay?\nFind all destinations that have at least two carriers.\n\n(These exercises are taken from pg 75 of R for Data Science - check there for more challenges.)"
  },
  {
    "objectID": "03-joining.html",
    "href": "03-joining.html",
    "title": "4  Combining Datasets",
    "section": "",
    "text": "Questions:\n\n\nHow do I combine dataframes?\n\n\nObjectives:\n\n\nUnderstanding keys\nExplore join functions\n\n\nKeypoints:\n\n\nDataframes get joined on key columns. The rows that are retained depends on the type of join performed"
  },
  {
    "objectID": "03-joining.html#joining",
    "href": "03-joining.html#joining",
    "title": "4  Combining Datasets",
    "section": "4.2 Joining",
    "text": "4.2 Joining\nOften you will want to combine data contained in more than one dataset. In this section we will look at the functions that help you do that.\n\n4.2.1 Key columns\nThe joining operation depends on the two datasets having some values in some column in common. The column in each dataset that allows you to combine columns is the key column. Consider these dataframes\n\n\n\n\nband_members\n\n# A tibble: 3 × 2\n  name  band   \n  <chr> <chr>  \n1 Mick  Stones \n2 John  Beatles\n3 Paul  Beatles\n\nband_instruments\n\n# A tibble: 3 × 2\n  name  plays \n  <chr> <chr> \n1 John  guitar\n2 Paul  bass  \n3 Keith guitar\n\n\nNote that the two dataframes have a column in common name."
  },
  {
    "objectID": "03-joining.html#join-functions",
    "href": "03-joining.html#join-functions",
    "title": "4  Combining Datasets",
    "section": "4.3 Join functions",
    "text": "4.3 Join functions\nJoin functions work to combine two dataframes side-by-side in some way. Usually they use one column as a base and add columns to that one from the other.\n\n4.3.1 left_join()\nThe most common sort of join is the left join. This takes one dataframe, considers it to be on the left of the join and combines the second dataframe on to it, skipping rows in the right dataframe that have nowhere to join\n\nleft_join( band_members, band_instruments, )\n\nJoining, by = \"name\"\n\n\n# A tibble: 3 × 3\n  name  band    plays \n  <chr> <chr>   <chr> \n1 Mick  Stones  <NA>  \n2 John  Beatles guitar\n3 Paul  Beatles bass  \n\n\nNote how the column in common name is used as the key through which to join and that the band_member Keith goes missing because it isn’t in the left dataframe, which is the reference.\n\n\n4.3.2 right_join()\nright_join() is the complementary function.\n\nright_join( band_members, band_instruments)\n\nJoining, by = \"name\"\n\n\n# A tibble: 3 × 3\n  name  band    plays \n  <chr> <chr>   <chr> \n1 John  Beatles guitar\n2 Paul  Beatles bass  \n3 Keith <NA>    guitar\n\n\nSee how this time Keith is retained as we’re joining to the right table as the base, but as he has no entry in the left table, an NA is used to fill the missing value.\n\n\n4.3.3 inner_join()\ninner_join() keeps only rows that are completely shared\n\ninner_join( band_members, band_instruments)\n\nJoining, by = \"name\"\n\n\n# A tibble: 2 × 3\n  name  band    plays \n  <chr> <chr>   <chr> \n1 John  Beatles guitar\n2 Paul  Beatles bass  \n\n\n\n\n4.3.4 full_join()\nfull_join() joins all rows as well as possible, generating NA as appropriate.\n\nfull_join( band_members, band_instruments)\n\nJoining, by = \"name\"\n\n\n# A tibble: 4 × 3\n  name  band    plays \n  <chr> <chr>   <chr> \n1 Mick  Stones  <NA>  \n2 John  Beatles guitar\n3 Paul  Beatles bass  \n4 Keith <NA>    guitar\n\n\n\n\n4.3.5 Joins with no common column names\nWhat can we do when there is no common column names? Consider this variant of band instruments\n\nband_instruments2\n\n# A tibble: 3 × 2\n  artist plays \n  <chr>  <chr> \n1 John   guitar\n2 Paul   bass  \n3 Keith  guitar\n\n\nThe name column is called artist - we can join by explicitly stating the column to join by\n\nleft_join( band_members, band_instruments2, by = c(\"name\" = \"artist\"))\n\n# A tibble: 3 × 3\n  name  band    plays \n  <chr> <chr>   <chr> \n1 Mick  Stones  <NA>  \n2 John  Beatles guitar\n3 Paul  Beatles bass"
  },
  {
    "objectID": "03-joining.html#binding-operations",
    "href": "03-joining.html#binding-operations",
    "title": "4  Combining Datasets",
    "section": "4.4 Binding operations",
    "text": "4.4 Binding operations\nThese allow you to paste dataframes together.\nbind_rows() sticks them together top-to-bottom.\n\nbind_rows(band_members, band_members)\n\n# A tibble: 6 × 2\n  name  band   \n  <chr> <chr>  \n1 Mick  Stones \n2 John  Beatles\n3 Paul  Beatles\n4 Mick  Stones \n5 John  Beatles\n6 Paul  Beatles\n\n\nNote the column names need not be identical for this to work. NAs are propogated as required.\n\nbind_rows(band_members, band_instruments)\n\n# A tibble: 6 × 3\n  name  band    plays \n  <chr> <chr>   <chr> \n1 Mick  Stones  <NA>  \n2 John  Beatles <NA>  \n3 Paul  Beatles <NA>  \n4 John  <NA>    guitar\n5 Paul  <NA>    bass  \n6 Keith <NA>    guitar\n\n\nbind_cols() sticks dataframes together side-by-side/\n\nbind_cols(band_members, band_instruments)\n\nNew names:\n• `name` -> `name...1`\n• `name` -> `name...3`\n\n\n# A tibble: 3 × 4\n  name...1 band    name...3 plays \n  <chr>    <chr>   <chr>    <chr> \n1 Mick     Stones  John     guitar\n2 John     Beatles Paul     bass  \n3 Paul     Beatles Keith    guitar\n\n\nNote how it doesn’t do any sensible matching - it’s just pasting them together. Repeated column names get modified. What happens if the dataframes aren’t of equal length?\n\ndata_4_rows <- tibble( names = letters[1:4], values = 1:4)\nbind_cols(band_members, data_4_rows)\n\nError in `bind_cols()`:\n! Can't recycle `..1` (size 3) to match `..2` (size 4)."
  },
  {
    "objectID": "03-joining.html#quiz",
    "href": "03-joining.html#quiz",
    "title": "4  Combining Datasets",
    "section": "4.5 Quiz",
    "text": "4.5 Quiz\n\nExamine the table1 and table4a datasets. Combine table4a to table1 to create two new columns. Ensure the columns make sense and retain data integrity."
  }
]