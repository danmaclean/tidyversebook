[
["loading-data-from-files.html", "Topic 9 Loading data from files 9.1 About this chapter 9.2 readr 9.3 Writing Files 9.4 readxl", " Topic 9 Loading data from files 9.1 About this chapter Questions: How do I get my data into R? Objectives: Loading a ‘.csv’ file Checking column contents Dealing with headers and column names Loading a specific sheet from a ‘.xlsx’ file. Keypoints: The readr and readxl packages contain functions for loading data from .csv and .xslx files. These functions help you to ensure that your data is loaded as you expect. 9.2 readr readr is a tool for loading data into R. As part of the tidyverse it is loaded when you use library(tidyverse) but can be loaded on its own with library(readr). We will use readr to load in data from a ‘flat’ .csv file. Most 9.2.1 read_csv() The main function is read_csv() which can read a standard comma seperated values file from disk into an R dataframe. There are a few variants of read_csv() which may be appropriate for different sorts of .csv file, but they all work the same. read_csv2() - reads semi-colon delimited files, which are commonly used where a comma is used as a decimal separator read_tsv() - reads tab delimited files read_delim() - reads files delimited by an arbitrary character The first argument to read_csv() is the path to the file to read. Here I’ll read a file on my Desktop that contains the diamonds data we’ve been using. read_csv(&quot;~/Desktop/diamonds.csv&quot;) ## Parsed with column specification: ## cols( ## carat = col_double(), ## cut = col_character(), ## color = col_character(), ## clarity = col_character(), ## depth = col_double(), ## table = col_double(), ## price = col_integer(), ## x = col_double(), ## y = col_double(), ## z = col_double() ## ) ## # A tibble: 53,940 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.21 Premium E SI1 59.8 61 326 3.89 3.84 2.31 ## 3 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4 0.29 Premium I VS2 62.4 58 334 4.20 4.23 2.63 ## 5 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 ## 6 0.24 Very Good J VVS2 62.8 57 336 3.94 3.96 2.48 ## 7 0.24 Very Good I VVS1 62.3 57 336 3.95 3.98 2.47 ## 8 0.26 Very Good H SI1 61.9 55 337 4.07 4.11 2.53 ## 9 0.22 Fair E VS2 65.1 61 337 3.87 3.78 2.49 ## 10 0.23 Very Good H VS1 59.4 61 338 4.00 4.05 2.39 ## # ... with 53,930 more rows On loading we see a column specification, read_csv() has guessed at what the columns should be and made those types. Its fine for the most part, but some of those columns we’d prefer to be factors. We can set our own column specification to force the column types on loading. We only have to do the ones that read_csv() gets wrong. Specifically, lets fix cut and color to a factor. We can do that with the col_types argument. read_csv(&quot;~/Desktop/diamonds.csv&quot;, col_types = cols( cut = col_factor(NULL), color = col_factor(NULL) ) ) ## # A tibble: 53,940 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;fctr&gt; &lt;fctr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.21 Premium E SI1 59.8 61 326 3.89 3.84 2.31 ## 3 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4 0.29 Premium I VS2 62.4 58 334 4.20 4.23 2.63 ## 5 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 ## 6 0.24 Very Good J VVS2 62.8 57 336 3.94 3.96 2.48 ## 7 0.24 Very Good I VVS1 62.3 57 336 3.95 3.98 2.47 ## 8 0.26 Very Good H SI1 61.9 55 337 4.07 4.11 2.53 ## 9 0.22 Fair E VS2 65.1 61 337 3.87 3.78 2.49 ## 10 0.23 Very Good H VS1 59.4 61 338 4.00 4.05 2.39 ## # ... with 53,930 more rows 9.2.2 Parser functions This works by assigning a parser function that returns a specific type to each column, here it’s col_factor(). There are parser functions for all types of data, and all of them can be used if read_csv() doesn’t guess your data properly. We won’t go into detail of all of them, just remember that if your numbers or dates or stuff won’t load properly, there’s a parser function that can help. The parser functions all have their own arguments, so we can manipulate those. We can see the NULL argument being passed to col_factor() above, which means ‘all values found should be used as levels of the factor’. This is a great default setting, but if we have a large file, it won’t help us find unexpected values. Consider a situation where we are certain we should only have the values Fair, Good and Very Good for cut in our diamonds data. We can make the parser function check this for us and give a warning if it finds anything else. read_csv(&quot;~/Desktop/diamonds.csv&quot;, col_types = cols( cut = col_factor(levels = c( &quot;Fair&quot; ,&quot;Good&quot;, &quot;Very Good&quot;)), color = col_factor(NULL) ) ) ## Warning in rbind(names(probs), probs_f): number of columns of result is not ## a multiple of vector length (arg 1) ## Warning: 35342 parsing failures. ## row # A tibble: 5 x 5 col row col expected actual file expected &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; actual 1 1 cut value in level set Ideal &#39;~/Desktop/diamonds.csv&#39; file 2 2 cut value in level set Premium &#39;~/Desktop/diamonds.csv&#39; row 3 4 cut value in level set Premium &#39;~/Desktop/diamonds.csv&#39; col 4 12 cut value in level set Ideal &#39;~/Desktop/diamonds.csv&#39; expected 5 13 cut value in level set Premium &#39;~/Desktop/diamonds.csv&#39; ## ... ................. ... ................................................................. ........ ................................................................. ...... ................................................................. .... ................................................................. ... ................................................................. ... ................................................................. ........ ................................................................. ## See problems(...) for more details. ## # A tibble: 53,940 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;fctr&gt; &lt;fctr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 &lt;NA&gt; E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.21 &lt;NA&gt; E SI1 59.8 61 326 3.89 3.84 2.31 ## 3 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4 0.29 &lt;NA&gt; I VS2 62.4 58 334 4.20 4.23 2.63 ## 5 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 ## 6 0.24 Very Good J VVS2 62.8 57 336 3.94 3.96 2.48 ## 7 0.24 Very Good I VVS1 62.3 57 336 3.95 3.98 2.47 ## 8 0.26 Very Good H SI1 61.9 55 337 4.07 4.11 2.53 ## 9 0.22 Fair E VS2 65.1 61 337 3.87 3.78 2.49 ## 10 0.23 Very Good H VS1 59.4 61 338 4.00 4.05 2.39 ## # ... with 53,930 more rows This time, we get a large number of warnings. Though the output is quite cryptic at first glance, read_csv() is complaining that it found values for cut that were not in the list we passed to the parser function. Hence we can use parsers to ensure we are loading in the data we expect and generate errors if not. 9.2.3 Headers and column names By default read_csv() uses the first line of the file for column names. Consider this toy example. toy_csv &lt;- &quot;a,b,c 1,2,3 4,5,6&quot; read_csv(toy_csv) ## # A tibble: 2 x 3 ## a b c ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 2 3 ## 2 4 5 6 The first line of the toy file becomes the column headings. This may not be appropriate, since there could be some metadata in the file toy_csv &lt;- &quot;some info about stuff a,b,c 1,2,3 4,5,6&quot; read_csv(toy_csv) ## Warning in rbind(names(probs), probs_f): number of columns of result is not ## a multiple of vector length (arg 1) ## Warning: 3 parsing failures. ## row # A tibble: 3 x 5 col row col expected actual file expected &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; actual 1 1 &lt;NA&gt; 1 columns 3 columns literal data file 2 2 &lt;NA&gt; 1 columns 3 columns literal data row 3 3 &lt;NA&gt; 1 columns 3 columns literal data ## # A tibble: 3 x 1 ## `some info about stuff` ## &lt;chr&gt; ## 1 a ## 2 1 ## 3 4 The loaded data gets really messed up, so we can skip a set number of lines if needed toy_csv &lt;- &quot;some info about stuff a,b,c 1,2,3 4,5,6&quot; read_csv(toy_csv, skip = 1) ## # A tibble: 2 x 3 ## a b c ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 2 3 ## 2 4 5 6 Alternatively, you might have comments that begin with a particular character. You can use the comment argument to skip those lines toy_csv &lt;- &quot;#some info about stuff #some more info #goodness, lots of INFO a,b,c 1,2,3 4,5,6&quot; read_csv(toy_csv, comment = &quot;#&quot;) ## # A tibble: 2 x 3 ## a b c ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 2 3 ## 2 4 5 6 The data might not have any column names at all, the first row may data. This situation is handled with col_names argument toy_csv &lt;- &quot;1,2,3 4,5,6&quot; read_csv(toy_csv, col_names = FALSE) ## # A tibble: 2 x 3 ## X1 X2 X3 ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 2 3 ## 2 4 5 6 So, read_csv() sets up arbitrary column names. We can specify column names if we wish toy_csv &lt;- &quot;a,b,c 1,2,3 4,5,6&quot; read_csv(toy_csv, col_names = c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;)) ## # A tibble: 3 x 3 ## x y z ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a b c ## 2 1 2 3 ## 3 4 5 6 9.2.4 Missing values There are many different ways of encoding missing values, you can tell read_csv() which character represents a missing value explicitly with the na argument. These values will all be loaded as proper NA. toy_csv &lt;- &quot;a,b,c 1,_,3 4,5,_&quot; read_csv(toy_csv, na = &quot;_&quot;) ## # A tibble: 2 x 3 ## a b c ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 NA 3 ## 2 4 5 NA 9.3 Writing Files A complementary functionto read_csv() write_csv() allows you to write a dataframe out to a ‘.csv’ file. The convention is straightforward, you need the name of the dataframe and the name of the file and path to write to. write_csv(diamonds, &quot;~/Desktop/my_data.csv&quot;) 9.4 readxl The readxl package is installed as part of the tidyvers install.packages() command, but it is not part of the core, so library(tidyverse) does not load it. You must do it explicitly with library(readxl). 9.4.1 read_excel() The main function is read_excel(), it’s similar to read_csv(). library(readxl) read_excel(&quot;~/Desktop/datasets.xls&quot;) ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5.0 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # ... with 140 more rows By default it loads the first worksheet, you can examine the sheets available with excel_sheets() excel_sheets(&quot;~/Desktop/datasets.xls&quot;) ## [1] &quot;iris&quot; &quot;mtcars&quot; &quot;chickwts&quot; &quot;quakes&quot; Then load in the one you want. read_excel(&quot;~/Desktop/datasets.xls&quot;, sheet = &quot;chickwts&quot;) ## # A tibble: 71 x 2 ## weight feed ## &lt;dbl&gt; &lt;chr&gt; ## 1 179 horsebean ## 2 160 horsebean ## 3 136 horsebean ## 4 227 horsebean ## 5 217 horsebean ## 6 168 horsebean ## 7 108 horsebean ## 8 124 horsebean ## 9 143 horsebean ## 10 140 horsebean ## # ... with 61 more rows Loading then follows the same pattern as for read_csv(), with a difference in the column specifications - in this package its much simpler. You can only specify type columnwise and the specification can only be one of “skip”, “guess”, “logical”, “numeric”, “date”, “text” or “list” - meaning you can’t do the advanced parsing as for read_csv(). A sample spec might look like read_excel( &quot;~/Desktop/datasets.xls&quot;, sheet = &quot;chickwts&quot;, col_types = c(&quot;numeric&quot;, &quot;text&quot;) ) ## # A tibble: 71 x 2 ## weight feed ## &lt;dbl&gt; &lt;chr&gt; ## 1 179 horsebean ## 2 160 horsebean ## 3 136 horsebean ## 4 227 horsebean ## 5 217 horsebean ## 6 168 horsebean ## 7 108 horsebean ## 8 124 horsebean ## 9 143 horsebean ## 10 140 horsebean ## # ... with 61 more rows "]
]
