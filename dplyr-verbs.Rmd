# dplyr Verbs

## About this chapter

1. Questions:
  - How do I manipulate tidy data?
2. Objectives:
  - Understanding the pipe syntax
  - Working with the 6 main functions
  - Overview of helper functions
3. Keypoints:
  - Tidy data can be operated on with six main functions that can quickly split, apply summaries and combine sub-groups of data

## dplyr

dplyr (data plier) is a tool for manipulating datasets. As part of the tidyverse it is loaded when you use `library(tidyverse)` but can be loaded on it's own with `library(dplyr)`. dplyr is set up as a small grammar, it has five main verbs that help you form small 'sentences' to get to your result.

The verbs are: 

  * `select()` picks variables based on their names.
  * `filter()` picks cases based on their values.
  * `mutate()` adds new variables that are functions of existing variables
  * `summarise()` reduces multiple values down to a single summary.
  * `arrange()` changes the ordering of the rows.
  
  A sixth function `group_by()` allows you to operate on subsets of the data.

## Pipe Syntax

The first argument to all these functions is the tidy table-like object (we'll start calling these data frames from here), so for our diamonds data set, then we use

```{r, eval = FALSE}
filter(diamonds, ... ) # ... stands in for other arguments
```

If we want to perform more than one step in series, we end up in the situation of having to save our result with a new name and working from there. This gets cumbersome quickly...

```{r, eval = FALSE}
diamonds2 <- filter(diamonds, ...)
diamonds3 <- select(diamonds2, ...)
diamonds4 <- mutate(diamonds3, ...)
```

To avoid this, there is a pipe operator - `%>%`. The purpose of the pipe is to take the thing on its left, and use it as the first argument of the thing on its right. So we can change that mess to

```{r, eval=FALSE}
diamonds %>% filter( ... ) %>% select( ... ) %>% mutate( ... )
```

Which is much more readable. Further we can put the right hand side of the pipe on a new line, such that we can get a very easy to read pattern.

```{r, eval=FALSE}
diamonds %>%
  filter( ... ) %>%
  select( ... ) %>% 
  mutate( ... )
```

If you want to save the result, you'll just put the usual assign at the top 

```{r, eval=FALSE}
filtered_diamonds <- 
diamonds %>%
  filter( ... ) %>%
  select( ... ) %>% 
  mutate( ... )
```

## select()

`select()` is probably the simplest verb. It lets you select whole columns from the dataframe, discarding others. This is most useful for working with huge datasets of many columns, or for extracting bits for ease of printing or presentation.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
```
```{r}
diamonds %>% 
  select(carat, cut) %>%
  head()
```

Shorthands include the `:` which lets you choose a range and `-` which can be read as `except` so leaves out the columns you state

```{r}
diamonds %>%
  select(depth:price) %>%
  head()
```

```{r}
diamonds %>%
  select( -x, -y, -z)  %>%
  head()
```

You can select columns with helpers, 

  * `starts_with()`
  * `ends_with()`
  * `contains()`
  * `num_range()`
  
Here are examples.

```{r}
diamonds %>%
  select( starts_with("c")) %>%
  head()
``` 
```{r}
diamonds %>%
  select( ends_with("e")) %>%
  head()
``` 
```{r}
diamonds %>%
  select( contains("l")) %>%
  head()
``` 
### rename()

Often when you're selecting columns to work on, you'll need to fix the names - `rename()` is useful for this. Let's fix that mis-spelled column

```{r}
diamonds %>% 
  rename( colour = color) %>%
  head()
```
## filter()

The `filter()` function lets you select rows (observations) from your data frame based on criteria you specify. Here I'll look for all rows with a value of `G` for the `color` variable (I'll also pipe the output to the `head()` function to view just the top of the output.)

```{r}
diamonds %>%
  filter( color == "G") %>%
  head()
```

The syntax is fairly clear, just pass the column you want to think about and the condition to keep the rows. Multiple conditions can be used and all must be true to keep a row.  

```{r}
diamonds %>%
  filter( color == "G", 
          cut == "Ideal" ) %>%
  head()
```

To make more complex queries, you'll need to combine comparisons and logical operators.

### Comparisons

R provides the following comparison operators 

 * `==` - strictly equal to
 * `!=` - not equal to
 * `>`, `<`, `>=`, `<=` - greater than, less than, greater or equal to, less or equal to

These all work as you might expect. Except for `==`.  Trying to use `==` on numbers with a decimal point is tricky because of rounding errors in the computer. See this: 

```{r}
(1 / 49) * 49 == 1
```

This statement is asking 'is 1 divided by 49, multiplied by 49, equal to 1'. The computer says `FALSE` because the computer can't store infinite numbers of decimal places. The rounding error is extremely small (down to the last 16th decimal place) but it is there. To deal with this rounding error we use the `near()` function, which checks numbers are the same to about the 8th decimal place.  

```{r}
near( (1 / 49) * 49, 1)
```

### Logical operators 

`filter()` uses combinations of R logical operators, these are `&` for `and`, `|` for `or` and `!` for `not`. You can build filters with these. Let's modify our query to find `color` `G` or `cut` `ideal`.

```{r}
diamonds %>%
  filter( color == "G" | cut == "Ideal" ) %>%
  head()
```

Note that the computer doesn't read this like it's English. Consider this

```{r, eval = FALSE}
diamonds %>%
  filter( color == "G" | "F") %>%
  head()
```

You might consider this to read `filter rows with color column equal to `G` or `F`. The computer doesn't read it like this. It needs more explicit statements 

```{r}
diamonds %>%
  filter( color == "G" | color == "F") %>%
  head()
```

Which can be cumbersome if you want to filter on one of many possible values. For that reason we have `%in%` , which works like

```{r}
diamonds %>%
  filter( color  %in% c("G", "F") ) %>%
  head()
```

You can select anything not in a list given to `%in%` with a judicious `!` (not), again this is a bit weird if you translate directly from English, as the not goes first. 
```{r}
diamonds %>%
  filter( ! color %in% c("G", "F") ) %>%
  head()
```

## mutate()

The `mutate()` function lets you add new columns based on values in other columns. Note that doing so to this data set makes it too big to print, so I'll `select()` the appropriate columns. 

```{r}
diamonds %>%
  mutate(price_per_carat = price / carat) %>%
  select(price, carat, price_per_carat) %>%
  head()
```

You can refer to columns straight after creating them, so you can minimise `mutate()`s

```{r}
diamonds %>%
  mutate(price_per_carat = price / carat) %>%
  mutate(depth_per_ppc = depth / price_per_carat) %>%
  select(depth_per_ppc, price_per_carat) %>%
  head()
```

### Functions in mutate()

You can create a new column with `mutate()` using pretty much any (vectorized) R function. It's a bit out of scope to explain what I mean by 'vectorized' but here's some examples.

```{r}
diamonds %>% 
  mutate(log_price = log(price)) %>%
  select(-x, -y, -z) %>% 
  head()
```

```{r}
diamonds %>%
  mutate( total_price = sum(price)) %>%
  select( -x, -y, -z) %>%
  head()
```

Observe how the same number is in all the rows in the last example, this highlights how this 'vectorized' function idea works. 

Briefly, vectorized functions work on whole columns at a time, not just single rows. So if it makes sense to treat each element of the column individually, the function will do that. Consider this column (here printed on its side) with the `log()` function.

```{r}
log(c(1,2,3))
```

You get back a column of numbers the same length as you put in, each item logged. With the `sum()` function it makes sense to return the sum of all the numbers in the column.

```{r}
sum(c(1,2,3))
```

So you get back a single number. The behaviour of `mutate()` then is akin to taking the whole column or columns you specify, apply whatever function you ask for and putting the resulting column in the dataframe. If the resulting column is too short, it just gets repeated until it fits. That is why we get repeats of the same number in the `sum()` example and why that number is the sum of all the prices.


### if_else()

One final vectorized function is `if_else()`, this is useful when you want to add a column that annotates the data with an arbitrary value based on values. Let's add a column called `cost` that can be `high` or `low` depending on the `price`. 

```{r}
diamonds %>%
  mutate( cost = if_else( price > 335, "high", "low")) %>%
  select( -x, -y, -z)
```

The `if_else()` function then just adds the first value ("high") if the condition is 'true' else it puts the second value.

## summarize() and group_by()

The `summarize()` function is a reductive function. It reduces entire dataframes to a single row, and returns an entirely new dataframe.

```{r}
diamonds %>%
  summarize( mean_price = mean(price) )
```

`summarize()` is best used with `group_by()` which helps split dataframes into subsets. The `summarize()` function will run once for each subset created by `group_by()`. Let's find the mean price for every colour of diamonds. We'll do this by grouping the `diamonds` dataframe on `color`, then summarising.

```{r}
diamonds %>%
  group_by(color) %>%
  summarize(mean_price = mean(price) ) 
```

This is where the power of dplyr starts to be obvious. Once we've got our dataframe into shape with the `select()`, `filter()` and `mutate()` functions, we can start to compute new information with `group_by()` and `summarize()` and some of the helper functions.

Let's group by two things, `color` and `cut`, and get the mean and standard deviation of `price`.

```{r}
diamonds %>%
  group_by(color, cut) %>%
  summarize( 
    mean_price = mean(price),
    sd = sd(price)
    )
```

Note how every combination of `color` and `cut` is made into subsets. 

### Helpful summarize() functions

There are numerous helpful summary functions. We've already seen `mean()` , `sum()` and `sd()`.

The function `n()` counts the number of items in a group. It doesn't need a column name to work on. 

```{r}
diamonds %>%
  group_by(color) %>%
  summarize( 
     count = n()
    )
```

Related is `n_distinct()` which counts the number of unique values in a group. This one needs to know which column of things you want to use. Let's see how many observations there are for each `cut` and how many different `color`s are observed in each `cut`

```{r}
diamonds %>%
  group_by(cut) %>%
  summarize( 
     items = n(),
     unique_colors = n_distinct(color)
    )
```

There are other helpful summary functions, here's a non-exhaustive list

  * `max()` or `min()`  - maximum or minimum value in a column
  * `median()` - median value in a column
  * `IQR()` - interquartile range (distance) between 25th and 75th percentile
  * `first()` or `last()` - first or last values in a column


## arrange()

The `arrange()` function is a straightforward function that helps you arrange the final table from `summarize()` a bit more nicely. It simply orders the rows in a way that you specify. 

```{r}
diamonds %>% 
  arrange(price) %>%
  head()
```

To sort biggest first, use `desc()`

```{r}
diamonds %>% 
  arrange(desc(price)) %>%
  head()
```

## Missing Values

Many (many!) datasets will have some missing values at some points. These are encoded in R as `NA`. They need to be dealt with explicitly as they mess up lots of calculations.

Look at the toy dataframe `incomplete` below

```{r, echo=FALSE}
incomplete <- data.frame(
  group =  rep(LETTERS[1:3], 2),
  size = c(10.4, NA, 8, 6, NA, NA) 
)
```

```{r}
incomplete
```
When we try to `summarize()` we get stuck

```{r}
incomplete %>%
  group_by( group ) %>%
  summarize(mean_size = mean(size))
```

The groups with any `NA` can't be calculated. We need to tell our helper function to remove `NA` before we work with it.

```{r}
incomplete %>%
  group_by( group ) %>%
  summarize(mean_size = mean(size, na.rm = TRUE))
```

This works! Though because the group `B` only had `NA` in it the formula for mean fails because we can't divide by `0` and we get `NaN` (not a number). 

You might think you can use `filter()` to get rid of any rows with NA in, but you get a weird result

```{r}
incomplete %>%
  filter(size != NA) %>%
  group_by( group ) %>%
  summarize(mean_size = mean(size))
```

By definition `NA` means `Not available`, which is a nice way of saying `don't know`, so, strictly, `x == NA` means "is `x` equal to something we don't know the value of?" To which the answer can only be `don't know`, for which R uses `NA`.  The result is that any comparison with `NA` in it is `NA`. `filter()` doesn't know whether any row passes so throws it out. You get no rows for `group_by()` to group.

If you want to check something is an `NA`, you can use `is.na()`

```{r}
incomplete %>%
  filter(! is.na(size)) %>%
  group_by( group ) %>%
  summarize(mean_size = mean(size))
```


Note that you lose the information for the `B` group, which may be important. 

You may want to pair these operations with an `n()` column to give you an idea of how many values you use to get your answer.

```{r}
incomplete %>%
  group_by( group ) %>%
  summarize(
    mean_size = mean(size, na.rm = TRUE),
    sample_size = n()
    )
```
```{r}
incomplete %>%
  filter(! is.na(size)) %>%
  group_by( group ) %>%
  summarize(mean_size = mean(size),
    sample_size = n()
    
    )
```

With a more complicated call, you can explicitly get the number of `NA`s. 

```{r}
incomplete %>%
  group_by( group ) %>%
  summarize(
    mean_size = mean(size, na.rm = TRUE),
    sample_size = n(),
    nas = sum(is.na(size))
    )
```

## Quiz

1. Load the package `nycflights13` which is a tidy data set of flight information out of New York. Look at the `flights` table that has been loaded and note the column names and types. 

2. The individual planes are identified by their `tailnum`. Which plane has the worst on-time record?

3. What time of day should you fly to avoid delays as much as possible?

4. For each destination compute the total minutes of delay?

5. Look at each destination. Can you find flights that are suspicously fast? I.E flights that might have a data entry error. 

6. Find all destinations that have at least two carriers. 

(These exercises are taken from pg 75 of [R for Data Science](http://r4ds.had.co.nz/) - check there for more challenges.)
